## 데이터베이스

### 1\. Key (기본키, 후보키, 슈퍼키 등등...) 에 대해 설명해 주세요.
> - 기본키: 릴레이션(테이블)의 튜플을 고유하게 식별할 수 있는 후보키 중 테이블의 대표 키로 선택된 속성(컬럼)들의 집합입니다. (고유성과 NOT NULL (개체 무결성)을 만족해야 함.)
> - 후보키: 릴레이션의 튜플을 고유하게 식별할 수 있는 최소한의 속성들의 집합입니다. (고유성(Unique)과 최소성(Minimal)을 만족하는 키들의 총집합이며, 이들 중 하나가 기본키로 선택됨.)
> - 슈퍼키: 릴레이션의 튜플을 고유하게 식별할 수 있는 모든 속성 집합입니다. (고유성은 만족하지만, 최소성은 만족하지 않아도 됨. 후보키와 기본키를 모두 포함하는 가장 큰 개념.)

*   기본키는 수정이 가능한가요?
> - 가능하지만, 권장되지 않습니다. 기본키는 튜플의 고유한 식별자이며, 다른 테이블의 외래키(Foreign Key)가 이를 참조하고 있을 수 있습니다(참조 무결성). 기본키를 수정하면 참조하는 모든 외래키를 연쇄적으로 업데이트(Update Cascade)해야 하거나, 무결성 위반으로 인해 수정이 실패할 수 있습니다. 따라서 기본키는 불변(Immutable)의 의미를 갖는 값으로 선정하는 것이 좋습니다.

*   사실 MySQL의 경우, 기본키를 설정하지 않아도 테이블이 만들어집니다. 어떻게 이게 가능한 걸까요?
> - MySQL(InnoDB 엔진 기준)은 기본키(Primary Key) 가 명시적으로 정의되지 않아도 테이블 생성을 허용합니다. 이는 InnoDB가 내부적으로 클러스터형 인덱스(Clustered Index) 를 반드시 가져야 하기 때문인데, 사용자가 지정하지 않은 경우 대체 키(Pseudo Primary Key)를 자동으로 생성합니다.
> - 작동 방식:
> 1. 기본키가 명시된 경우 → 해당 기본키가 클러스터형 인덱스로 사용됩니다.
> 2. 기본키가 없고, UNIQUE NOT NULL 컬럼이 존재하는 경우 → 그 컬럼을 클러스터형 인덱스로 자동 사용합니다.
> 3. 그마저도 없을 경우 → InnoDB가 내부적으로 숨겨진 6바이트 크기의 ROW ID(일종의 내부 기본키) 를 생성하여 각 레코드를 식별합니다.
> - 즉, MySQL은 기본키가 없어도 테이블을 만들 수 있지만, 실제 내부적으로는 항상 레코드를 유일하게 식별하기 위한 식별자(Internal Cluster Key) 를 유지하고 있습니다. 따라서 사용자 입장에서는 기본키가 없어 보여도, InnoDB는 내부적으로 보이지 않는 기본키를 자동으로 만들어 테이블의 정렬 및 데이터 접근을 관리하는 구조입니다.

*   외래키 값은 NULL이 들어올 수 있나요?
> - 네, NULL이 들어올 수 있습니다. 외래키 칼럼에 NULL이 들어오는 것은 "참조하는 부모 테이블의 어떤 튜플과도 현재 튜플이 관련이 없다"는 의미를 갖습니다. (외래키 칼럼을 정의할 때 NOT NULL 제약조건을 명시적으로 추가하면 NULL 값이 들어올 수 없습니다.) NULL이 아닌 값이 들어온다면, 반드시 참조 무결성 제약조건에 따라 부모 테이블의 기본키 값 중 하나와 일치해야 합니다.

*   어떤 칼럼의 정의에 UNIQUE 키워드가 붙는다고 가정해 봅시다. 이 칼럼을 활용한 쿼리의 성능은 그렇지 않은 것과 비교해서 어떻게 다를까요?
> - UNIQUE 키워드가 붙으면 해당 칼럼에 유니크 인덱스(Unique Index)가 자동으로 생성됩니다.
> - 이 칼럼을 활용하는 경우 성능 차이:
>   - SELECT (읽기) 성능: WHERE 절에서 해당 칼럼을 사용할 경우, 인덱스를 통한 검색이 가능해져 테이블 전체를 탐색하는 것보다 훨씬 빠르게 데이터를 찾을 수 있습니다. (성능 향상)
>    - DML (쓰기/수정) 성능: INSERT 또는 UPDATE 시, 새로운 값이 들어올 때마다 UNIQUE 제약조건을 만족하는지 검사하는 추가 작업이 필요하며, 데이터가 변경될 때마다 인덱스 자체도 함께 갱신하는 오버헤드가 발생하여 성능이 저하될 수 있습니다. (성능 저하)

### 2\. RDB와 NoSQL의 차이에 대해 설명해 주세요.
> - **RDB(관계형 데이터베이스) **: 테이블 기반의 고정된 스키마를 사용하며, 조인을 통해 데이터 간의 관계와 ACID 속성을 이용한 강력한 일관성을 보장합니다.
> - **NoSQL**: 문서, 키-값 등 다양한 모델을 사용하며 유연하고 동적인 스키마를 갖습니다. NoSQL은 주로 BASE 모델을 추구하며 강력한 일관성 대신 수평 확장(Scale-out)을 통한 대용량 처리와 분산에 강점을 가집니다.

*   NoSQL의 강점과, 약점이 무엇인가요?
> - 강점: 수평 확장이 용이하여 대량의 트래픽과 데이터를 저렴하게 처리할 수 있고, 유연한 스키마 덕분에 데이터 구조 변화에 민첩하게 대응할 수 있어 빠른 개발에 유리합니다.
> - 약점: 강력한 데이터 일관성(ACID)을 보장하기 어려우며, 조인 기능이 제한적이거나 없기 때문에 복잡한 관계 질의에는 적합하지 않습니다. 또한, 데이터 모델이 다양하여 표준화된 쿼리 언어(SQL)가 없어 학습 곡선이 높습니다.

*   RDB의 어떠한 특징 때문에 NoSQL에 비해 부하가 많이 걸릴 "수" 있을까요? (주의: 무조건 NoSQL이 RDB 보다 빠르다라고 생각하면 큰일 납니다!)
> - RDB는 데이터의 무결성을 보장하는 ACID 트랜잭션 처리 과정에서 NoSQL보다 더 큰 부하가 걸릴 수 있습니다. 구체적으로는 데이터의 일관성을 유지하기 위한 복잡한 잠금(Locking) 메커니즘과 트랜잭션 로그 기록 오버헤드가 발생하며, 정규화된 구조 때문에 데이터를 가져올 때 발생하는 조인(JOIN) 연산이 대규모 데이터에서 성능 병목을 유발할 수 있습니다.

*   NoSQL을 활용한 경험이 있나요? 있다면, 왜 RDB를 선택하지 않고 해당 DB를 선택했는지 설명해 주세요.
> 저는 MongoDB를 활용하여 식당 장소 정보 및 리뷰 크롤링 데이터를 저장하는 시스템을 구축한 경험이 있습니다. <br>
> **1. 데이터 구조의 유연성**:
식당 장소 정보와 리뷰 데이터는 비정형 요소(예: 리뷰 내용, 태그, 영업 시간의 변동 등)가 많고, 추후 서비스 확장이나 크롤링 대상 사이트의 변화에 따라 필드 구조가 유연하게 변경될 수 있는 특성을 가집니다. RDB는 고정된 스키마를 요구하기 때문에 구조 변경 시 테이블 전체를 수정하는 번거로움과 서비스 중단 위험이 따르지만, MongoDB는 스키마리스(Schema-less) 또는 동적 스키마(Dynamic Schema) 방식이라 이러한 변화에 민첩하게 대응할 수 있어 개발 속도를 높일 수 있었습니다.<br>
> **2. 단일 문서(Document) 기반의 빠른 조회 성능**:
식당 정보를 조회할 때, 일반적으로 식당의 기본 정보, 메뉴, 리뷰 등이 함께 필요합니다. RDB에서 이 정보를 가져오려면 여러 테이블 간의 복잡한 조인(JOIN) 연산이 필수적이며, 이는 대규모 데이터에서 성능 병목을 유발합니다. 반면, MongoDB는 식당 정보를 하나의 문서(Document) 안에 포함(Embed)할 수 있어, 데이터를 가져올 때 단 한 번의 쿼리로 모든 관련 정보를 얻을 수 있으므로 조회 성능이 월등히 빠릅니다.<br>
> **3. 대용량 데이터 처리 및 수평 확장 용이성**: 
크롤링을 통해 수집된 데이터는 그 양이 방대하며 지속적으로 증가합니다. RDB는 주로 서버 성능을 높이는 수직 확장(**Scale-up**)에 의존하는 반면, MongoDB는 서버를 쉽게 늘려(Scale-out) 용량과 트래픽을 분산 처리하는 수평 확장(**Sharding**)에 강점을 가집니다. 대용량 데이터를 저렴하고 효율적으로 저장하고 처리하기 위해서는 분산 아키텍처를 지원하는 MongoDB가 더 적합하다고 판단했습니다.<br>

### 3\. 트랜잭션이 무엇이고, ACID 원칙에 대해 설명해 주세요.
> - **트랜잭션(Transaction):** 데이터베이스의 상태를 변환시키는 논리적인 작업 단위입니다. 여러 개의 SQL 명령어들을 하나의 묶음으로 처리하여, 전체 작업이 완벽하게 성공되거나(Commit), 하나라도 실패하면 전체가 취소(Rollback)되어 데이터베이스의 일관성을 유지하는 것을 목표로 합니다.
> - **ACID 원칙**(**A**tomicity, **C**onsistency, **I**solation, **D**urability): 데이터베이스 트랜잭션이 안전하게 수행되는 것을 보장하기 위한 네 가지 핵심 속성입니다.
| 속성 | 한국어 명칭 | 설명 |
|------|--------------|------|
| A | 원자성 (Atomicity) | 트랜잭션 내의 모든 작업은 전부 성공하거나, 아니면 전부 실패해야 한다. (All or Nothing) |
| C | 일관성 (Consistency) | 트랜잭션이 실행되기 전후에 데이터베이스는 항상 일관된 상태를 유지해야 한다. (정의된 규칙이나 제약조건을 위반하지 않아야 함) |
| I | 격리성 (Isolation) | 동시에 실행되는 트랜잭션들은 서로 간에 독립적으로 수행되어야 하며, 각 트랜잭션은 다른 트랜잭션의 연산을 알 수 없다. |
| D | 영속성 (Durability) | 트랜잭션이 성공적으로 완료(Commit)되면, 그 결과는 시스템 장애(정전, 서버 다운 등)에도 불구하고 영구적으로 보존되어야 한다. |

*   ACID 원칙 중, Durability를 DBMS는 어떻게 보장하나요?
> - DBMS는 주로 로그(Log) 메커니즘을 사용하여 영속성을 보장합니다. 트랜잭션이 Commit되는 순간, 변경된 데이터가 실제 디스크의 데이터 파일에 기록되기 전에, 그 변경 내용이 담긴 **Transaction Log**를 먼저 영구 저장 장치(디스크)에 기록합니다. 이를 WAL(Write Ahead Logging) 또는 Force Logging이라고 한다.
> - Commit 후 시스템 장애가 발생하더라도, 재시작 시 DBMS는 로그 파일을 확인하여 Commit된 변경 사항은 데이터 파일에 **Redo**(복구)함으로써 데이터의 영구적인 보존을 보장합니다.

*   트랜잭션을 사용해 본 경험이 있나요? 어떤 경우에 사용할 수 있나요?
> - (대표적인 상황) 쇼핑몰 서비스 - 상품 주문 시 재고 감소, 주문 정보 생성, 결제 정보 기록까지 세 단계를 하나의 논리적인 작업 단위로 묶기 위해 트랜잭션을 사용할 수 있습니다.
사용하는 경우: 데이터의 정합성(Consistency)이 가장 중요하며, 여러 개의 데이터베이스 작업이 분리될 수 없는 단일한 업무 흐름을 구성할 때 사용해야 합니다. (대표적인 예시: 계좌 이체, 상품 주문 및 재고 처리, 복합적인 데이터 입력 등)

*   읽기에는 트랜잭션을 걸지 않아도 될까요?
> - 아닙니다. 읽기 연산에도 트랜잭션은 필수적입니다.
> - 단순히 한 번의 조회로 끝나는 쿼리라면 트랜잭션의 필요성이 낮지만, 동일 트랜잭션 내에서 여러 번의 읽기가 수행되거나 읽은 데이터에 기반하여 후속 로직을 처리해야 하는 경우 **격리성**(Isolation)을 보장해야 합니다.
> - 트랜잭션을 걸지 않거나 격리 수준이 낮으면, 다른 트랜잭션의 중간 변경사항이 읽히는 Dirty Read, 같은 데이터를 두 번 읽었는데 값이 달라지는 Non-Repeatable Read와 같은 동시성 문제가 발생하여 데이터 일관성이 깨질 수 있습니다. DBMS는 이러한 문제 방지를 위해 읽기 트랜잭션에도 격리 수준을 적용합니다.

### 4\. 트랜잭션 격리 레벨에 대해 설명해 주세요.
- **트랜잭션 격리 레벨**(Isolation Level): 동시에 여러 트랜잭션이 실행될 때, 각 트랜잭션이 다른 트랜잭션의 변경 내용을 어디까지 볼 수 있도록 허용할지 정의하는 표준 수준입니다. (데이터의 일관성(Consistency)과 동시성(Concurrency) 간의 균형을 맞추기 위해 존재) 격리 레벨이 높아질수록 데이터 일관성은 높아지지만, 동시성은 낮아져 성능 저하가 발생할 수 있습니다.

  | 레벨 (낮음 → 높음) | 설명 | 발생하는 문제 |
  |---------------------|------|----------------|
  | Read Uncommitted | 커밋되지 않은(Uncommitted) 다른 트랜잭션의 변경 내용도 읽을 수 있음. | Dirty Read |
  | Read Committed | 커밋된(Committed) 데이터만 읽을 수 있음. | Non-Repeatable Read, Phantom Read |
  | Repeatable Read | 트랜잭션 내에서 동일한 데이터를 반복 조회해도 항상 같은 결과를 보장. | Phantom Read |
  | Serializable | 가장 엄격한 격리 레벨. 트랜잭션을 순차적으로(Serial) 실행하는 것처럼 완벽히 격리. | 없음 (모든 동시성 문제 해결) |

  - Dirty Read: 커밋되지 않은 데이터(임시 변경된 데이터)를 읽는 현상.
  - Non-Repeatable Read: 한 트랜잭션이 같은 행을 두 번 읽었는데, 그 사이에 다른 트랜잭션이 그 행을 수정하고 커밋하여 두 번째 읽기 결과가 달라지는 현상.
  - Phantom Read: 한 트랜잭션이 특정 조건으로 행 집합을 조회했는데, 그 사이에 다른 트랜잭션이 해당 조건에 맞는 새로운 행을 삽입(Insert)하고 커밋하여 두 번째 조회 결과에 '유령'처럼 새로운 행이 나타나는 현상.


*   모든 DBMS가 4개의 레벨을 모두 구현하고 있나요? 그렇지 않다면 그 이유는 무엇일까요?
> - X. 모든 DBMS가 4개의 표준 레벨을 모두 구현하지는 않습니다.
> - SQL Server나 Oracle 같은 일부 DBMS는 표준 외에 Snapshot Isolation 같은 자체적인 격리 레벨을 제공하거나, 표준 레벨 중 일부를 다른 방식으로 구현합니다.
> - Oracle의 경우, Read Committed 레벨이 가장 기본이며, Repeatable Read는 별도로 지원하지 않고 Serializable로 대체됩니다. 이는 Oracle이 Undo 영역을 활용하는 다중 버전 동시성 제어(MVCC) 방식을 기본으로 채택하여, Read Committed에서도 대부분의 Non-Repeatable Read 문제를 발생시키지 않기 때문입니다.
> 
*   만약 MySQL을 사용하고 있다면, (InnoDB 기준) Undo 영역과 Redo 영역에 대해 설명해 주세요.
> - MySQL의 InnoDB 스토리지 엔진은 데이터 복구 및 트랜잭션 격리(특히 MVCC)를 위해 이 두 영역을 핵심적으로 사용합니다.
>   - Undo 영역 (로그):
>     - 목적: 트랜잭션의 **원자성**(Atomicity)과 **격리성**(Isolation)을 보장합니다.
>     - 역할: 트랜잭션이 데이터를 변경할 때, 변경 전의 이전 데이터(Old Version)를 보관합니다. 트랜잭션이 실패하여 Rollback이 필요할 경우, 이 로그를 사용하여 데이터를 원래 상태로 되돌립니다(원자성). 또한, **MVCC**(Multi-Version Concurrency Control)를 구현하여 다른 트랜잭션이 이전 버전의 데이터를 읽게 하여 Non-Repeatable Read 등의 문제를 방지합니다(격리성).
>   - Redo 영역 (로그):
>     - 목적: 트랜잭션의 **영속성**(Durability)을 보장합니다.
>     - 역할: 트랜잭션이 데이터를 변경했을 때, 그 변경 내용을 순서대로 디스크에 기록합니다. 트랜잭션이 Commit된 후 시스템에 장애(정전 등)가 발생하여 데이터가 디스크에 완전히 기록되지 못했더라도, 재시작 시 이 Redo 로그를 사용하여 Commit된 내용을 **복구**(Redo)함으로써 데이터의 영속성을 보장합니다.

*   그런데, 스토리지 엔진이 정확히 무엇을 하는 건가요?
>  - **스토리지 엔진(Storage Engine) **은 데이터베이스 관리 시스템(DBMS)의 가장 하위 계층에서 실제로 디스크에 데이터를 저장하고, 읽고, 관리하는 역할을 담당하는 핵심 모듈입니다.
> - DBMS의 **핵심 기능(SQL 파싱, 권한 관리, 트랜잭션 처리 등) **은 DBMS 코어에서 담당하고, 스토리지 엔진은 "어떻게" 데이터를 저장할지 결정합니다.
> - MySQL의 경우 InnoDB, MyISAM 등 여러 스토리지 엔진을 플러그인 방식으로 지원하며, 각 엔진마다 트랜잭션 지원 여부, 잠금 방식, 인덱싱 구조, 성능 특성이 다릅니다. 예를 들어, InnoDB는 트랜잭션(ACID)과 행 레벨 잠금을 지원하지만, MyISAM은 트랜잭션을 지원하지 않고 테이블 레벨 잠금만 지원합니다.

### 5\. 인덱스가 무엇이고, 언제 사용하는지 설명해 주세요.
> - 인덱스(Index): 데이터베이스에서 검색 속도를 향상시키기 위해 사용하는 자료구조입니다. 흔히 책의 색인처럼, 원하는 데이터를 빠르게 찾기 위해 특정 열(Column)의 값을 정렬해 별도로 관리합니다. 내부적으로는 주로 B+Tree나 Hash 구조를 사용하며, 인덱스가 존재하면 WHERE, JOIN, ORDER BY, GROUP BY 연산의 탐색 범위를 크게 줄일 수 있습니다.

*   일반적으로 인덱스는 수정이 잦은 테이블에선 사용하지 않기를 권합니다. 왜 그럴까요?
> - 인덱스는 데이터를 빠르게 검색하기 위한 자료구조이지만, 테이블 데이터가 변경될 때마다 인덱스도 함께 갱신해야 하는 오버헤드(Overhead)가 발생합니다.
>   1) INSERT (삽입 시): 테이블에 새로운 행이 삽입되면, 해당 행의 키 값은 인덱스 구조(대부분 B-Tree) 내의 적절한 위치에 삽입되어야 합니다. 이는 **페이지 분할**(Split)과 같은 추가적인 디스크 I/O 작업을 유발합니다.
>   2) UPDATE (수정 시): 인덱스 키로 사용된 칼럼의 값이 수정되면, 기존 인덱스 항목은 삭제되고 새로운 값으로 삽입되는 두 단계의 작업이 발생하여 비용이 높습니다.
>   3) DELETE (삭제 시): 테이블에서 행이 삭제되면 인덱스에서도 해당 항목을 삭제해야 합니다.
> - 이처럼 쓰기(Write) 작업이 빈번할 경우, 인덱스 유지 보수 비용이 검색 성능 향상 이득을 상쇄하고도 남게 되어 전체적인 DBMS 성능을 저하시킬 수 있습니다.

*   앞 꼬리질문에 대해, 그렇다면 인덱스에서 사용하지 않겠다고 선택한 값은 위 정책을 그대로 따라가나요?
> - YES. 인덱스가 없는 일반 칼럼이라 할지라도, 그 값이 변경될 때는 테이블의 데이터 페이지 자체를 수정해야 합니다. DBMS는 변경된 내용을 디스크에 반영하기 위해 **트랜잭션 로그(Redo Log) **를 기록해야 합니다. 인덱스 갱신만큼 복잡한 구조 변경 작업은 없지만, 디스크 I/O와 로깅 오버헤드는 여전히 발생합니다. 다만, 인덱스가 있는 칼럼은 데이터 페이지 변경과 인덱스 페이지 변경 두 가지 모두를 수행해야 하므로, 인덱스가 없는 칼럼보다 수정 부하가 훨씬 큽니다.

*   ORDER BY/GROUP BY 연산의 동작 과정을 인덱스의 존재여부와 연관지어서 설명해 주세요.
> - ORDER BY (정렬)나 GROUP BY (그룹핑) 연산은 기본적으로 CPU와 메모리를 많이 사용하는 고비용 연산입니다.
> - 인덱스가 없는 경우: DBMS는 쿼리 결과를 가져온 후, 디스크에 임시 저장 공간(보통 Sort Buffer나 Temp Table)을 사용하여 데이터를 **Filesort**(직접 정렬)하거나 그룹핑 작업을 수행합니다. 데이터 크기가 메모리 용량을 초과하면 디스크 I/O가 발생하여 성능이 크게 저하되는 성능 병목이 발생합니다.
> - 인덱스가 있는 경우: 인덱스는 데이터가 이미 정렬된 상태로 저장되어 있는 자료구조(예: B-Tree). 쿼리에서 인덱스의 순서와 같은 방향으로 ORDER BY나 GROUP BY를 요청하면, DBMS는 인덱스를 처음부터 순차적으로 읽는 것만으로 별도의 정렬/그룹핑 과정 없이 결과를 바로 반환할 수 있습니다. 이를 통해 Filesort 과정이 생략되어 성능이 극적으로 향상됩니다.

*   기본키는 인덱스라고 할 수 있을까요? 그렇지 않다면, 인덱스와 기본키는 어떤 차이가 있나요?
> - 기본키는 인덱스라고 할 수 있습니다. 대부분의 RDB(특히 InnoDB)에서 기본키를 정의하면 DBMS가 해당 칼럼에 자동으로 **Clustered Index**를 생성합니다.
> 차이점:
> - 기본키(Primary Key): 데이터베이스 논리적 제약조건의 하나입니다. 튜플을 고유하게 식별하며 NOT NULL을 강제하는 개념입니다.
> - 인덱스(Index): 디스크에 저장된 데이터를 빠르게 찾기 위한 물리적인 자료구조입니다. 기본키는 이 인덱스를 생성하는 논리적 기반이 됩니다.

*   그렇다면 외래키는요?
> - 외래키(Foreign Key)는 그 자체가 인덱스는 아닙니다. 하지만 외래키가 정의될 때, 대부분의 DBMS(특히 MySQL의 InnoDB)는 참조 무결성을 확인하는 작업의 효율성을 높이기 위해 **자동으로 인덱스(Non-Clustered Index) **를 생성해 줍니다.
> - 외래키의 역할은 참조 무결성을 보장하는 것이고, 인덱스는 이 무결성 검사 속도를 높이기 위한 보조 수단입니다.

*   인덱스가 데이터의 물리적 저장에도 영향을 미치나요? 그렇지 않다면, 데이터는 어떤 순서로 물리적으로 저장되나요?
> - 클러스터형 인덱스(Clustered Index)는 물리적 저장 순서에 영향을 미칩니다.
> - 클러스터형 인덱스 (기본키): 인덱스의 리프 페이지가 곧 실제 데이터 행(튜플) 자체를 포함합니다. 따라서 데이터는 클러스터형 인덱스 키 값의 물리적인 순서대로 디스크에 저장됩니다. 테이블당 오직 하나만 가질 수 있습니다.
> - 비클러스터형 인덱스 (Non-Clustered Index): 데이터의 물리적 저장 순서에 영향을 미치지 않습니다. 리프 페이지는 인덱스 키와 해당 데이터 행을 찾아가기 위한 **주소 값**(Primary Key 또는 물리적 주소)만 가지고 있습니다. 데이터 자체는 클러스터형 인덱스의 순서를 따릅니다.
> 
*   우리가 아는 RDB가 아닌 NoSQL (ex. Redis, MongoDB 등)는 인덱스를 갖고 있나요? 만약 있다면, RDB의 인덱스와는 어떤 차이가 있을까요?
> - 네, 대부분의 NoSQL DB도 인덱스를 갖고 있습니다.
> - MongoDB: RDB와 유사하게 B-Tree 기반의 인덱스를 사용하며, 단일 필드, 복합 필드, Unique, TTL(Time-To-Live) 등 다양한 인덱스 타입을 지원하여 빠른 쿼리 성능을 보장합니다.
> - Redis: Key-Value Store로, 기본적으로 메모리에 데이터를 저장하며, Key 자체가 해시 테이블의 인덱스 역할을 하므로 별도의 명시적 인덱스가 필요하지 않습니다.
> - RDB 인덱스와의 차이점:
>   - 자료구조의 다양성: RDB가 주로 B-Tree 인덱스에 집중하는 반면, NoSQL은 데이터 모델에 따라 지리 공간(Geospatial), 텍스트 검색(Text Index) 등 특화된 인덱스를 제공합니다.
>   - 트랜잭션 오버헤드: NoSQL(특히 MongoDB)의 인덱스는 RDB만큼 엄격한 ACID 트랜잭션과 잠금 메커니즘을 거치지 않기 때문에, 인덱스 갱신에 드는 트랜잭션 부하가 RDB보다 낮을 수 있습니다.

*   (A, B) 와 같은 방식으로 인덱스를 설정한 테이블에서, A 조건 없이 B 조건만 사용하여 쿼리를 요청했습니다. 해당 쿼리는 인덱스를 탈까요?
> - 아닙니다. 해당 쿼리는 인덱스를 타지 못할 가능성이 높습니다. 이는 복합 인덱스(Composite Index)의 핵심인 선행 칼럼의 원칙(Leftmost Prefix Rule) 때문입니다.
> - 복합 인덱스 (A, B)는 A, B 순서로 데이터가 정렬되어 있습니다. 인덱스를 사용하려면 반드시 인덱스의 첫 번째 칼럼인 A를 조건으로 사용해야 합니다.
> - A 조건 없이 B 조건만 사용하는 것은 정렬된 목록의 중간 값만 가지고 검색을 시도하는 것과 같기 때문에, DBMS는 인덱스를 활용할 수 없다고 판단하고 Full Table Scan을 수행할 가능성이 높습니다. (매우 예외적으로 B 칼럼의 선택도가 극도로 높아 인덱스 스캔이 효율적이라고 판단하는 경우가 있을 수 있지만, 일반적인 경우는 '타지 못한다'입니다.)

### 6\. RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요.

> - **RDBMS의 클러스터링**은 여러 DB 서버를 하나의 논리적 시스템처럼 구성하여 고가용성과 부하 분산을 달성하는 방식입니다. 일반적으로 **Active-Standby**(이중화) 또는 **Active-Active** 형태로 구성되며, 하나의 노드가 장애를 일으켜도 다른 노드가 즉시 서비스를 이어받을 수 있습니다. 반면, **레플리케이션**은 **Master–Slave 구조**로 동작하며, 마스터에서 발생한 변경 사항을 슬레이브로 비동기 또는 반동기 방식으로 복제합니다. 읽기 부하를 분산하고, 장애 시 슬레이브를 승격(Promotion)하여 복구 시간을 단축할 수 있습니다.
> 
> - **NoSQL**에서는 시스템 특성상 수평 확장성(Scalability)과 가용성(Availability) 이 우선이기 때문에, 대부분 **클러스터링 + 레플리케이션 + 파티셔닝** 을 동시에 지원합니다. 예로 MongoDB는 **Replica Set**(복제)와 **Sharded Cluster**(분산 저장)를 함께 구성하여 노드 장애에도 데이터 접근이 가능하게 설계합니다.


*   이러한 분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요?
> 분산 환경에서는 **2PC (Two-Phase Commit) ** 나 **3PC (Three-Phase Commit) ** 프로토콜을 사용해 트랜잭션 일관성을 보장합니다.  
> 하지만 네트워크 지연이나 노드 장애가 잦은 환경에서는 완벽한 일관성을 유지하기 어렵기 때문에, **CAP 이론**에 따라 RDBMS는 **Consistency**를 우선하고, NoSQL은 **Availability**와 **Partition tolerance**를 더 중시하는 방향으로 설계됩니다.  
> NoSQL에서는 주로 **Eventually Consistent**(최종적 일관성) 모델을 사용합니다.


*   마스터, 슬레이브 데이터 동기화 전 까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?
> 비동기 복제에서는 마스터에 커밋된 데이터가 아직 슬레이브로 전송되지 않았을 수 있습니다.<br>
> 이를 보완하기 위한 대표적 방법 세가지가 있습니다:
> - **Semi-Synchronous Replication:** 마스터가 슬레이브 중 최소 하나로부터 ACK(수신 확인)를 받기 전까지 커밋을 완료하지 않음.
> - **GTID (Global Transaction ID):** 트랜잭션에 전역 식별자를 부여해 동기화 상태를 정밀하게 추적.
> - **Read-After-Write Consistency 보장:** 특정 세션에서만 마스터로 읽기 요청을 강제.


*   다중 트랜잭션 상황에서의 Deadlock 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.

> 다중 트랜잭션 환경에서 두 트랜잭션이 서로가 점유한 자원을 기다리며 무한 대기하는 상태를 **데드락(Deadlock)** 이라고 합니다.  
> 예시로, 트랜잭션 A가 Row X를 점유하고 Y를 기다리는 동안, 트랜잭션 B가 Y를 점유하고 X를 기다리면 교착 상태가 발생합니다.  
> 해결 방법은 다음과 같습니다:
> - **Lock Timeout 설정:** 일정 시간 후 자동 롤백.
> - **Lock 순서 정렬:** 모든 트랜잭션이 동일한 자원 획득 순서를 따르도록 설계.
> - **낙관적 락(Optimistic Lock):** 충돌 발생 시점에만 검증 후 재시도.
> - **DBMS Deadlock Detection:** InnoDB 등은 주기적으로 Wait-for Graph를 검사하여 교착 상태를 감지하고, 비용이 적은 트랜잭션을 강제 종료합니다.


*   샤딩 방식은 무엇인가요? 만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?

> **샤딩**은 **데이터를 수평(horizontal) 분할**하여 여러 노드에 나누어 저장하는 방식입니다. 예를 들어 사용자 ID 기준으로 데이터를 여러 서버에 분산 저장하면, 단일 DB의 저장 한계와 부하를 줄일 수 있습니다.  
> - **레플리케이션**: 데이터 복제(중복 저장)로 **가용성** 향상  
> - **샤딩**: 데이터 분산으로 **확장성** 향상
>
> 제가 분산 환경을 설계한다면, 읽기 부하가 많고 장애 복구가 중요한 서비스에는 레플리케이션, 데이터가 방대하고 트래픽이 급증하는 서비스에는 샤딩을 선택할 것입니다. 또한 두 방식을 혼합 구성하는 **Sharded Replica Cluster** 방식을 통해 성능과 안정성을 동시에 확보할 수 있습니다.

### 7\. 정규화가 무엇인가요?

> 정규화(Normalization)는 **데이터의 중복을 최소화**하고 **이상현상(Anomaly)을 방지하기 위해** 관계형 데이터베이스의 스키마를 체계적으로 **분해**하는 과정입니다. 정규화의 목표는 데이터 무결성(Data Integrity)을 유지하고, 갱신·삽입·삭제 시 일관성 문제를 예방하는 것입니다.

*   정규화를 하지 않을 경우, 발생할 수 있는 이상현상에 대해 설명해 주세요.

> - **삽입 이상 (Insertion Anomaly)**: 특정 속성을 삽입하기 위해 다른 속성값을 강제로 입력해야 하는 문제. (ex. 아직 주문이 없는 고객을 추가하려면 주문번호를 임의로 넣어야 하는 상황 발생)
> - **갱신 이상 (Update Anomaly)**: 동일한 데이터가 여러 행에 중복되어 있을 경우, 일부만 수정되어 불일치가 생기는 문제. (ex. 부서 이름이 여러 행에 중복되어 있을 때 일부만 변경되면 데이터 불일치 발생)
> - **삭제 이상 (Deletion Anomaly)**: 특정 데이터를 삭제하면서 의도치 않게 다른 정보까지 함께 손실되는 문제. (ex. 주문이 하나뿐인 고객의 주문을 삭제하면 고객 정보까지 사라지는 경우)

*   각 정규화에 대해, 그 정규화가 진행되기 전/후의 테이블의 변화에 대해 설명해 주세요.
> - 제1정규형(1NF): 각 컬럼이 **원자값**을 가지도록 테이블을 분해합니다. (한 칸 당 하나의 값)
> - 제2정규형(2NF): 부분 함수 종속을 제거하여, 기본키의 일부에만 종속된 속성을 별도 테이블로 분리합니다. (예: (학생ID, 과목ID) → 과목명)
> - 제3정규형(3NF): **이행적 함수 종속(Transitive Dependency) **을 제거하여, 비키(=키가 아닌) 속성이 다른 비키 속성에 의존하지 않도록 합니다.
> - BCNF(Boyce–Codd Normal Form): 모든 결정자가 후보키가 되도록 하여, 함수 종속성을 보다 엄격히 통제합니다.

*   정규화가 무조건 좋은가요? 그렇지 않다면, 어떤 상황에서 역정규화를 하는게 좋은지 설명해 주세요.
> - 정규화는 데이터 일관성과 무결성 유지에는 탁월하지만, 실무에서는 조회 성능(Join Cost) 문제가 발생할 수 있습니다. 지나치게 세분화된 테이블은 다중 조인을 유발하며, 대용량 데이터 분석이나 실시간 조회 성능을 저하시킬 수 있습니다.  
> - 따라서 트랜잭션 중심의 OLTP 시스템에서는 정규화를 유지하지만, 분석 중심의 OLAP 시스템이나 읽기 빈도가 높은 서비스에서는 **역정규화(Denormalization) **를 통해 성능을 최적화하기도 합니다.
> - 역정규화는 일부 중복을 허용하고, 조회 효율을 위해 데이터를 결합하거나 요약본(Aggregated Table)을 미리 생성하는 기법입니다.
>   - ex. 실시간 대시보드용 집계 테이블(자주 사용하는 Join 결과를 별도 테이블로 저장)

### 8\. View가 무엇이고, 언제 사용할 수 있나요?
> - **View**는 하나 이상의 테이블에서 파생된 **가상의 논리적 테이블**(Virtual Table)입니다. 실제 데이터를 저장하지 않고, **SELECT 쿼리의 결과 집합**을 정의 형태로 저장하여 필요할 때마다 동적으로 조회합니다.
>   - 데이터 추상화, 보안, 쿼리 재사용성 측면에서 활용됨.
>   - 복잡한 다중 조인 쿼리를 하나의 View로 정의 시 개발자는 단일 테이블처럼 간단히 접근 가능.
> - **View의 활용 목적:**
>   - 보안적으로 접근 제어: 민감한 컬럼(예: 급여, 주민등록번호)을 제외한 View를 제공함으로써 접근 제한 가능.
>   - 쿼리 단순화: 자주 사용하는 복잡한 조인이나 집계 쿼리를 View로 정의해 재사용성을 높임.
>   - 논리적 독립성: 실제 테이블 구조가 변경되더라도, View를 통해 기존 쿼리의 호환성 유지 가능.
>   - 다른 사용자 인터페이스 통합: 동일 데이터를 다른 관점에서 보여줄 때 유용. (예: 판매팀 View, 재무팀 View)

*   그렇다면, View의 값을 수정해도 실제 테이블에는 반영되지 않나요?

> View는 기본적으로 읽기 전용 구조로서 대부분의 경우는 값을 수정하더라도 실제 테이블에 반영되지 않습니다. 단, 단일 테이블을 직접 참조하는 단순 View라면 예외적으로 실제 테이블에 변경이 반영될 수 있습니다. 
> - 갱신 가능한 View(Updatable View)의 조건:  
> View가 갱신 가능하려면 다음을 모두 만족해야 합니다. (AND 조건 / 하나라도 위배 시 non-updatable)
>   - 단일 기본 테이블만을 참조할 것.
>   - JOIN, GROUP BY, DISTINCT, UNION, ORDER BY 등을 포함하지 않을 것.
>   - 집계 함수나 계산식이 없을 것.
>   - View의 각 컬럼이 기본 테이블의 실제 컬럼과 직접 연결되어 있을 것.
> - 예:
> 
>   ```sql
>   CREATE VIEW emp_view AS
>   SELECT empno, ename, sal
>   FROM emp
>   WHERE deptno = 10;
>   
>   UPDATE emp_view
>   SET sal = 4000
>   WHERE empno = 1001;
>   ```
>   → 실제 `emp` 테이블의 `sal` 값이 변경된다.
> 
> 2. DBMS별 동작 차이
> * **MySQL / MariaDB**: 단순 View는 갱신 가능하며,
>   `WITH CHECK OPTION`을 추가하면 View 조건을 벗어난 데이터 수정이 자동으로 차단됨.
> * **Oracle / SQL Server**: 단순 View는 갱신 가능하나, 복잡한 View는 불가능.
> * **PostgreSQL**: View는 기본적으로 읽기 전용이지만, `INSTEAD OF TRIGGER`를 통해 갱신 동작을 정의할 수 있음.

### 9\. DB Join이 무엇인지 설명하고, 각각의 종류에 대해 설명해 주세요.
> **Join**은 관계형 데이터베이스에서 **두 개 이상의 테이블을 공통 키(Join Key) **를 기준으로 결합하여 하나의 결과 집합을 생성하는 연산입니다.  
> Join은 데이터의 관계성을 표현하고, 정규화된 테이블 간 데이터를 조합하여 의미 있는 정보를 도출할 수 있도록 합니다.  
> SQL에서는 INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN, CROSS JOIN 등의 구문이 사용됩니다.
> - **Join의 종류와 특징:**
>   - INNER JOIN: 양쪽 테이블의 교집합만 반환.
>   - LEFT OUTER JOIN: 왼쪽 테이블의 모든 행을 반환하며, 일치하지 않는 오른쪽 데이터는 NULL로 채움.
>   - RIGHT OUTER JOIN: 오른쪽 테이블 기준으로 LEFT JOIN과 반대 동작을 수행.
>   - FULL OUTER JOIN: 양쪽 테이블의 합집합을 반환하며, 일치하지 않는 값은 NULL로 채움.
>   - CROSS JOIN: 두 테이블의 모든 조합(Cartesian Product)을 반환.

*   사실, JOIN은 상당한 시간이 걸릴 수 있기에 내부적으로 다양한 구현 방식을 사용하고 있습니다. 그 예시에 대해 설명해 주세요.

> DB 엔진은 상황에 따라 다양한 Join 알고리즘을 선택합니다.
> * **Nested Loop Join**: 한 테이블의 각 행에 대해 다른 테이블을 반복 탐색. 작은 테이블 + 인덱스가 있는 경우 유리.
> * **Hash Join**: 한쪽 테이블을 해시 테이블로 변환해 매칭. 대용량 비정렬 데이터에 효율적.
> * **Merge Join(Sort-Merge)**: 두 입력이 정렬되어 있을 때 순차적으로 병합. 인덱스 정렬 상태가 유지될 경우 유리.

*   그렇다면 입력한 쿼리에서 어떤 구현 방식을 사용하는지는 어떻게 알 수 있나요?

> 입력한 쿼리가 어떤 방식으로 실행되는지는 **실행 계획(Execution Plan)** 을 통해 확인할 수 있습니다.
> 실행 계획은 DBMS가 쿼리를 처리하기 위해 선택한 **조인 순서, 조인 알고리즘(Nested Loop, Hash Join, Merge Join 등), 인덱스 사용 여부, 접근 경로** 등을 보여주는 정보입니다.
> 
> MySQL에서는 `EXPLAIN` 명령을 사용하여 각 테이블의 **조인 유형(join type)**, **사용된 인덱스(key)**, **예상 행 수(rows)** 등을 확인할 수 있습니다. 이를 통해 쿼리가 의도한 대로 최적화되어 있는지, 불필요한 풀 스캔이 발생하는지를 진단할 수 있습니다.
> 
> PostgreSQL에서도 `EXPLAIN` 또는 `EXPLAIN ANALYZE` 명령을 사용하여 실행 계획을 확인할 수 있습니다. 특히 `EXPLAIN ANALYZE`는 쿼리를 실제로 실행하여 **예상치뿐 아니라 실제 실행 시간과 처리된 행 수**까지 보여주므로, 성능 튜닝 시 더 정확한 분석이 가능합니다.
> 

*   앞 질문들을 통해 인덱스의 중요성을 알 수 있었는데, 그렇다면 JOIN의 성능도 인덱스의 유무의 영향을 받나요?

> - 인덱스(Index)는 Join 성능에 직접적인 영향을 미칩니다.
> - Join Key에 인덱스가 존재하면 랜덤 접근을 최소화하여 검색 비용 **O(log N) **으로 접근이 가능합니다.
> - 반면 인덱스가 없을 경우, **Full Table Scan**으로 인해 O(N*M)의 연산이 필요하고 성능 저하가 발생합니다.

*   3중 조인 부터는 동작 방식이 약간 바뀝니다. 어떻게 동작하는지, 그리고 그 방식이 성능에 어떠한 영향을 주는지 설명해 주세요.

> 3중 조인부터는 DBMS가 두 테이블을 먼저 조인해 **중간 결과(Intermediate Result) ** 를 만든 뒤, 그 결과를 세 번째 테이블과 다시 조인하는 **이진 조인(Binary Join) ** 방식으로 처리합니다.
이 과정에서 **조인 순서** 와 **조인 알고리즘(Nested Loop, Hash Join, Merge Join 등) ** 이 성능을 결정짓는 핵심 요소가 됩니다.  
> 3개 이상의 테이블을 조인할 때는 **조인 순서 최적화(Join Order Optimization) ** 가 특히 중요합니다.  
> 옵티마이저는 가능한 모든 조합을 평가하려 하지만, 테이블 수가 많아질수록 탐색 공간이 O(n!)으로 폭증하기 때문에, 실제 DBMS는 **비용 기반 옵티마이저(CBO) ** 를 사용하여 통계정보를 기반으로 일부 후보만 탐색합니다. 필요한 경우 개발자는 조인 순서를 고정하는 힌트(Hint) 를 사용하여 옵티마이저의 선택을 제어하기도 합니다.  
> 만약 카디널리티(결과 행 수)가 큰 테이블을 먼저 조인하면, 중간 결과가 과도하게 커져 메모리 스필(Spill)과 디스크 I/O가 급격히 증가합니다. 반대로 작은 테이블이나 필터링 효과가 큰 테이블을 먼저 조인하면 불필요한 데이터가 조기에 제거되어 성능이 향상됩니다. 또한 중간 결과에는 인덱스가 존재하지 않으므로, 비효율적인 실행 계획이 선택되면 이후 단계에서 Table Full Scan 이 발생할 수 있습니다.  
>  따라서 3중 조인 이상에서는 **조인 순서, 인덱스 설계, 통계 정보 갱신**을 통해 옵티마이저가 최적의 실행 계획을 세울 수 있도록 관리하는 것이 매우 중요합니다.

### 10\. B-Tree와 B+Tree에 대해 설명해 주세요.

> - **B-Tree**는 이진 탐색 트리를 확장한 **다진 탐색 트리(Multiway Search Tree)** 로, 각 노드가 여러 개의 키와 자식 포인터를 가집니다. 모든 리프 노드가 같은 깊이에 위치하며 트리의 균형을 유지합니다.
> - **B+Tree**는 B-Tree의 확장 구조로, **모든 실제 데이터가 리프 노드에만 저장**되고, 리프 노드들이 **연결 리스트** 형태로 이어져 있습니다.
> - 두 구조 모두 **데이터베이스와 파일 시스템의 인덱스 구조**로 널리 사용됩니다.

*   그렇다면, B+Tree가 B-Tree에 비해 반드시 좋다고 할 수 있을까요? 그렇지 않다면 어떤 단점이 있을까요?

> - 그렇지 않습니다. B+Tree는 모든 데이터가 리프 노드에 저장되므로, 원하는 키가 내부 노드에 있더라도 리프까지 내려가야 하는 추가 디스크 접근 비용이 발생할 수 있습니다. 즉, 단일 키 조회 속도는 B-Tree보다 약간 느릴 수 있습니다. 그러나 대규모 데이터 환경에서는 범위 검색 효율성이 훨씬 크기 때문에 대부분의 DB는 B+Tree를 사용합니다.  
> 
> **B+Tree 장점**
> * 리프 노드 간 연결로 인해 **Sequential Scan**(순차 접근) 및 **범위 검색(Range Query) ** 이 매우 효율적입니다.
> * 상위 노드에는 키 값만 저장되므로 메모리 내 탐색이 빠르고, 트리의 높이가 낮아 **디스크 I/O를 최소화**할 수 있습니다.
> * 삽입과 삭제 시에도 트리의 균형이 자동으로 유지되어 **일관된 탐색 성능**을 제공합니다.
> 
> **B+Tree 단점**
> * 실제 데이터가 모두 리프 노드에 있으므로, **단일 키 검색 시 항상 리프까지 내려가야** 합니다.
> * B-Tree에 비해 메모리 내 **데이터 지역성(Locality) ** 이 떨어질 수 있어 일부 환경에서는 접근 속도가 느려질 수 있습니다.
> 

*   DB에서 RBT를 사용하지 않고, B-Tree/B+Tree를 사용하는 이유가 있을까요?

> - RBT는 메모리 내 탐색 효율이 높지만, 디스크 기반 접근에는 부적합합니다. 그 이유는 RBT의 각 노드가 작고 균등하게 분포되어 있어 디스크 블록(Locality of Reference) 효율이 낮기 때문입니다.   
> - 반면, B-Tree/B+Tree는 노드 크기를 디스크 페이지(Page, 보통 4KB) 단위로 구성하여 한 번의 I/O로 여러 키를 읽을 수 있게 설계되어 있습니다. 따라서 디스크 접근 최소화가 중요한 DB 인덱스 구조에서는 RBT보다 B-Tree 계열이 훨씬 효율적입니다.

*   오름차순으로 정렬된 인덱스가 있다고 할 때, 내림차순 정렬을 시도할 경우 성능이 어떻게 될까요? B-Tree/B+Tree의 구조를 기반으로 설명해 주세요.

> B+Tree 인덱스는 리프 노드가 오름차순으로 연결되어 있으므로, 내림차순 정렬 시에는 **반대 방향으로 순회해야** 합니다.  
> 구조상 가능하지만, 역방향 탐색 과정에서 **캐시 적중률이 낮고 페이지 프리패칭 효율이 떨어져 약간의 성능 저하**가 발생합니다.  
> 하지만 인덱스 자체를 새로 만들 필요는 없으며, 쿼리 옵티마이저가 동일 인덱스를 역순으로 활용합니다.  
> 다만 대량의 데이터를 정렬해야 하는 ORDER BY DESC 연산에서는 인덱스 범위 스캔(Index Range Scan) 보다 정렬 연산 비용이 높아질 수 있습니다.

### 11\. DB Locking에 대해 설명해 주세요.

> Locking은 **동시성 제어(Concurrency Control) **를 위해 데이터베이스에서 사용하는 핵심 메커니즘입니다.  
> 여러 트랜잭션이 동시에 동일한 자원(행, 테이블 등)에 접근할 때 **데이터 무결성**(Consistency)을 보장하기 위해, 자원에 대한 접근을 제한하는 것입니다.  
> DBMS는 일반적으로 **Lock Manager**를 통해 Lock의 획득, 대기, 해제, 타임아웃을 관리합니다.  
> * Lock의 주요 유형:
>   - **Shared Lock (S-Lock **: 읽기(Read) 전용 접근을 허용하며, 다른 트랜잭션도 동시에 읽을 수 있다. 하지만 쓰기는 금지된다.
>   - **Exclusive Lock (X-Lock) **: 쓰기(Write) 작업을 위한 Lock으로, 해당 자원에는 다른 트랜잭션이 읽기·쓰기 모두 불가능하다.
>   - **Intention Lock (IS/IX) **: 테이블 단위 잠금을 위한 계층적 Lock으로, 하위 레벨(Row Lock 등)의 Lock 존재를 명시한다.
>   - **Deadlock (교착상태) **: 두 트랜잭션이 서로의 Lock 해제를 기다리며 무한 대기 상태에 빠지는 문제. DB는 이를 감지해 트랜잭션 중 하나를 강제 종료(Rollback)한다.


*   Optimistic Lock/Pessimistic Lock에 대해 설명해 주세요.

> - **Optimistic Lock (낙관적 락) **
>   * 동시에 접근해도 충돌이 거의 없다고 가정하고, 트랜잭션 종료 시점에 충돌을 감지합니다.
>   * 일반적으로 **버전 필드(Version Number) **나 **타임스탬프(Timestamp) **를 사용해 변경 전후를 비교합니다.
>   * 충돌 시 갱신을 거부하고 재시도하도록 애플리케이션 레벨에서 처리합니다.
>   * 장점: Lock 오버헤드가 없고, 읽기 중심 시스템에 적합.
>   * 단점: 쓰기 충돌이 잦은 환경에서는 Rollback 빈도가 높아짐.
> 
> - **Pessimistic Lock (비관적 락) **
>   * 충돌 가능성이 높다고 가정하고, **데이터 접근 시 즉시 물리적 Lock을 획득**합니다.
>   * DBMS에서 `SELECT ... FOR UPDATE` 또는 `SELECT ... FOR SHARE` 구문을 사용해 명시적으로 설정합니다.
>   * 장점: 경쟁 조건(Race Condition)을 원천 차단 가능.
>   * 단점: Lock 유지 시간이 길면 다른 트랜잭션이 대기 상태로 쌓여 시스템 병목을 유발.


*   물리적인 Lock을 건다면, 만약 이를 수행중인 요청에 문제가 생겨 비정상 종료되면 Lock이 절대 해제되지 않는 문제가 생길 수도 있을 것 같습니다. DB는 이를 위한 해결책이 있나요? 없다면, 우리가 이 문제를 해결할 수 없을까요?

> 물리적 Lock을 사용하는 경우, 트랜잭션 수행 중 비정상 종료(프로세스 크래시, 네트워크 단절 등)가 발생하면 **Lock이 영구적으로 유지될 위험**이 있습니다. 이를 방지하기 위해 DBMS는 다음과 같은 메커니즘을 내장합니다:
>
> * **트랜잭션 로그(Undo/Redo Log) **와 **세션 모니터링(Session Monitor) **을 통해 비정상 종료된 세션의 Lock을 자동 해제.
> * **Timeout 설정**: 일정 시간 동안 Lock을 획득하지 못하면 트랜잭션을 강제 중단하고 Lock을 회수.
> * **Crash Recovery Process**: DB 재시작 시 Undo Log를 통해 미완료 트랜잭션을 롤백하고 Lock 상태를 정리.
>
> 만약 DB의 자동 회복 기능이 제대로 작동하지 않는 경우, 응용 계층에서도 **Heartbeat 기반 세션 관리**나 **Lock Table 모니터링**을 통해 Lock 상태를 주기적으로 검증하고, 오래된 세션을 강제로 종료(Kill)하도록 설계할 수 있습니다.


### 12\. 트래픽이 높아질 때, DB는 어떻게 관리를 할 수 있을까요?

> 트래픽 증가로 DB 부하가 심해질 경우, **수평적 확장(Scale-out) **과 **수직적 확장(Scale-up) **을 조합해 대응합니다.
> DBMS는 CPU·메모리·I/O 리소스 사용량에 따라 성능 한계점이 다르므로, **읽기/쓰기 분리, 캐싱, 샤딩, 레플리케이션** 등을 통해 병목을 분산시킵니다.
> * 일반적인 대응 전략:
> - **Read Replica**(읽기 복제본): 쓰기 연산은 Master에서 처리하고, 읽기 요청은 복제본(Slave)으로 분산. 이를 통해 읽기 부하를 다중 노드에 분배.
>   예: MySQL Replication, PostgreSQL Streaming Replication.
>
> - **Connection Pooling**: 애플리케이션에서 DB 연결을 재사용하도록 하여, 커넥션 생성 비용을 줄임.
>   예: HikariCP, PgBouncer.
>
> - **Query Optimization & Index Tuning**: 실행 계획(Execution Plan)을 점검하고, 불필요한 Full Table Scan을 피하도록 인덱스를 최적화. 통계정보를 최신으로 유지해 옵티마이저가 최적의 계획을 선택하도록 함.
>
> - **Caching Layer 추가**: Redis, Memcached와 같은 인메모리 캐시를 도입해 반복 조회를 DB 대신 캐시에서 처리. Hot Data(자주 접근되는 데이터)만 캐싱하여 DB의 읽기 부하를 크게 감소 가능.
>
> - **Batch 처리 / Queue 처리**: 실시간으로 처리할 필요가 없는 요청은 큐(Kafka, RabbitMQ 등)에 적재하고 비동기적으로 처리.

*   DB 서버를 분산하지 않고, 트래픽을 감당할 수 있는 방법은 없을까요?

> 분산(Replication, Sharding)을 적용하지 않고도 단일 DB 인스턴스에서 트래픽을 일정 수준까지 흡수하는 방법은 다음과 같습니다.
>
> * **Scale-up**: 더 높은 사양의 CPU, 메모리, SSD 스토리지로 서버를 업그레이드. (단, 하드웨어적 한계 존재)
> * **인덱스 최적화 및 파티셔닝**: 대용량 테이블을 논리적으로 분할하여 I/O를 병렬 처리. (수평적 샤딩 없이도 내부적으로 I/O 효율을 높임)
> * **Data Archiving**: 오래된 데이터(Cold Data)를 별도 스토리지로 이관하여, 활성 데이터셋(Working Set)의 크기를 줄임.
> * **Statement Caching**: 동일 SQL을 반복 실행할 때 파싱/컴파일 비용을 줄이기 위해 Prepared Statement를 재사용.
>
> 궁극적으로 트래픽이 지속적으로 증가한다면, 단일 노드 한계로 인해 **Scale-out**(샤딩, 리플리카)으로 전환할 수밖에 없다.


### 13\. Schema가 무엇인가요?
> Schema는 **데이터베이스의 논리적 구조**를 정의한 청사진입니다. 즉, 테이블, 뷰, 인덱스, 제약조건, 트리거 등 데이터베이스 객체들의 정의와 관계를 기술하는 메타데이터(Metadata) 집합입니다. (데이터 자체가 아닌 데이터의 구조, 형식, 관계를 정의한다는 점에서 “데이터의 설계도”에 해당.)

*   Schema의 3계층에 대해 설명해 주세요.
> ANSI-SPARC 아키텍처에 따라 데이터베이스는 **3-Level Architecture**으로 구분됩니다. (데이터 독립성을 보장하고, 물리적 저장 구조와 응용 프로그램 간의 결합도를 낮추기 위한 모델)
>
> * **외부 스키마 (External Schema, View Level) **
>   * 사용자의 관점에서 데이터가 어떻게 보이는지를 정의한다.
>   * 사용자별/응용별로 필요한 데이터만 선택적으로 표시한다.
>   * 예: 영업부는 판매 테이블만, 인사부는 직원 테이블만 접근.
>   * SQL의 View가 대표적 구현 예시다.
> * **개념 스키마 (Conceptual Schema, Logical Level) **
>   * 데이터베이스 전체의 논리적 구조를 정의한다.
>   * 모든 엔터티(Entity), 속성(Attribute), 관계(Relationship), 제약조건을 포괄한다.
>   * ERD(Entity-Relationship Diagram)가 이 수준을 시각화한 것이다.
>   * 사용자 관점의 데이터들을 통합하여 일관된 논리 모델을 제공한다.
> * **내부 스키마 (Internal Schema, Physical Level) **
>   * 데이터가 물리적으로 어떻게 저장되는지를 정의한다.
>   * 인덱스 구조(B+Tree 등), 파티션, 블록 단위 저장 방식, 페이지 크기 등을 포함한다.
>   * DBMS가 실제 디스크 I/O를 최적화하기 위해 사용하는 수준이다.
>
> 이러한 다층 구조를 통해 응용 프로그램은 논리적/물리적 데이터 구조 변경에도 영향을 받지 않으며, 이는 **논리적·물리적 데이터 독립성**을 보장합니다.


### 14. DB의 Connection Pool에 대해 설명해 주세요.

> Connection Pool은 **DB와의 물리적 커넥션을 재사용하기 위해 관리하는 풀링 메커니즘**입니다.
> DB 커넥션 생성은 TCP 세션 수립, 인증, 세션 초기화 등 비용이 크기 때문에, 이를 매 요청마다 새로 만드는 것은 비효율적입니다.
> 따라서 Connection Pool은 애플리케이션 시작 시 일정 개수의 커넥션을 미리 만들어 풀(Pool)에 보관하고, 요청이 들어오면 사용 가능한 커넥션을 즉시 대여(checkout)하여 반환(checkin)하는 방식으로 동작합니다.
> 대표적으로 **HikariCP**, **C3P0**, **DBCP**, **PgBouncer** 등이 있습니다.

* DB와 Client가 Connection을 어떻게 구성하는지 설명해 주세요.

> 일반적으로 DB 커넥션은 **TCP 기반의 세션**으로 구성됩니다.
> 클라이언트 애플리케이션이 JDBC나 ODBC 드라이버를 통해 DB에 연결 요청을 보내면, 다음 절차로 세션이 만들어집니다:
>
> 1. **TCP 3-way handshake**를 통해 물리적 연결이 수립됩니다.
> 2. **DB Authentication** 과정이 수행되어 계정·비밀번호·권한이 검증됩니다.
> 3. **Session Context**이 생성되어, 트랜잭션 상태·세션 변수·커서 정보 등을 관리합니다.
> 4. 이후 SQL 요청은 동일한 세션을 통해 송수신됩니다.
>
> Connection Pool은 이 과정을 최초 1회만 수행하고, 이후 연결을 재사용하여 애플리케이션이 빠르게 DB에 접근할 수 있게 합니다.
> 사용이 끝난 커넥션은 닫지 않고 Pool로 반환되어 다음 요청에서 재사용됩니다.
> 이때 Pool은 유효성 검사 쿼리(`validationQuery`)를 통해 연결 상태를 주기적으로 확인하며, 유휴 시간 초과 시 연결을 종료해 자원을 회수합니다.

### 15. Table Full Scan, Index Range Scan에 대해 설명해 주세요.

> **Table Full Scan**은 테이블의 모든 행을 순차적으로 읽는 방식이고,
> **Index Range Scan**은 인덱스를 이용해 특정 범위의 행만 탐색하는 방식입니다.
> 옵티마이저는 각 방식의 **cost**를 비교해 더 효율적인 쪽을 자동으로 선택합니다.
> 일반적으로 **행 선택도(Selectivity) **가 낮을수록 Index Scan이, 높을수록 Full Scan이 유리합니다.

* 가끔은 인덱스를 타는 쿼리임에도 Table Full Scan 방식으로 동작하는 경우가 있습니다. 왜 그럴까요?

> 옵티마이저는 쿼리 실행 전에 **통계정보(Statistics) **를 기반으로 비용을 계산합니다.
> 인덱스를 사용할 수 있는 조건이라도, 다음과 같은 이유로 Full Scan을 선택할 수 있습니다:
>
> 1. **선택도(Selectivity)가 낮음** — 조건에 맞는 행이 많을 경우, 인덱스 랜덤 I/O보다 테이블 순차 I/O가 더 빠르다고 판단.
> 2. **비검색성 조건(Non-sargable Predicate) ** — 컬럼에 함수, 연산, 타입 변환이 적용된 경우(`WHERE LOWER(name)=...`) 인덱스를 활용하지 못함.
> 3. **통계정보 부정확** — 데이터 분포에 대한 통계가 오래되어 옵티마이저가 잘못된 비용 추정을 하는 경우.
> 4. **복합 인덱스 불일치** — 인덱스의 선행 컬럼이 조건절에 포함되지 않으면 인덱스 탐색이 불가능함.
> 5. **병렬 처리 전략 선택** — 대용량 테이블에서 병렬 Full Scan이 인덱스보다 효율적일 수 있음.
> 6. **조인 순서 변경** — 옵티마이저가 조인 최적화를 위해 전체 스캔을 선호할 때.
>
> 즉, 인덱스 존재 여부보다 **데이터 분포·쿼리 구조·옵티마이저 판단**이 더 중요합니다.

* COUNT (개수를 세는 쿼리)는 어떻게 동작하나요? COUNT(1), COUNT(*), COUNT(column)의 동작 과정에는 차이가 있나요?

> * **COUNT(*) **
>   * NULL 여부와 상관없이 **모든 행(row)을 카운트**.
>   * 일반적으로 옵티마이저는 `COUNT(*)`를 최적화하여, 가능한 경우 인덱스 리프만 스캔하거나 통계 데이터를 사용.
>   * InnoDB 등 트랜잭션형 스토리지 엔진은 즉시 반환할 수 있는 전체 행 수 메타데이터를 유지하지 않기 때문에, 실제 스캔을 수행해야 함.
> * **COUNT(1) **
>   * 각 행마다 상수 `1`을 반환해 카운트. 결과적으로 `COUNT(*)`와 완전히 동일하게 처리되며, 실행 계획도 같음.
>   * 과거 일부 DB에서 내부 최적화 차이가 있었으나, 현대 엔진에서는 동일한 연산으로 인식됨.
> * **COUNT(column) **
>   * 지정된 컬럼의 **NULL이 아닌 행만 카운트**.
>   * 즉, NULL이 존재하면 `COUNT(*)`보다 작은 값이 나옴.
>   * 성능상으로는 동일하나, NULL 검사 연산이 추가됨.
>
> **정리**
>
> * `COUNT(*)` = `COUNT(1)` → 모든 행을 센다.
> * `COUNT(column)` → NULL이 아닌 행만 센다.
> * 성능 차이는 거의 없으며, DBMS 내부 최적화에 따라 `COUNT(*)`가 가장 표준적이고 안정적입니다.
> * 대규모 테이블에서는 전체 스캔을 피하기 위해 **집계 테이블**이나 **물리 카운터 컬럼**을 사용하는 것이 일반적입니다.

### 16. SQL Injection에 대해 설명해 주세요.

> SQL Injection: 사용자 입력이 SQL 문에 직접 삽입되어 쿼리의 구조가 조작되는 보안 취약점.  
> 예를 들어,
>
> ```sql
> SELECT * FROM users WHERE id = ' " + input + " ';
> ```
>
> 에서 사용자가 `' OR 1=1 --`를 입력하면, 인증이 우회되는 공격이 발생합니다. (-> 데이터 유출, 삭제, 권한 상승 등 심각한 피해 발생 가능)

* 그렇다면, 우리가 서버 개발 과정에서 사용하는 수많은 DB 라이브러리들은 이 문제를 어떻게 해결할까요?

> 대부분의 현대적 DB 라이브러리와 ORM은 **Prepared Statement**를 사용해 이 문제를 원천적으로 차단합니다.
>
> * **Prepared Statement의 Parameter Binding**
>   * SQL 구조와 데이터를 분리.
>   * DB는 쿼리 템플릿(`SELECT * FROM users WHERE id = ?`)을 미리 컴파일하고, 값은 런타임 시 안전하게 바인딩.
>   * 파라미터는 리터럴 데이터로만 처리되므로, 구문 자체를 변경할 수 없음.
> * **ORM/Query Builder의 내부 보호 메커니즘**
>   * Hibernate, JPA, MyBatis, Sequelize 등 ORM 프레임워크는 내부적으로 Prepared Statement를 사용함.
>   * 단, 문자열로 직접 쿼리를 조합하는 경우(`nativeQuery`, `@Query`, `raw SQL`)에는 여전히 인젝션 위험이 존재.
> * **입력 검증과 화이트리스트**
>   * 컬럼명·테이블명 등 **식별자(identifier) **는 바인딩이 불가능하므로, 반드시 허용된 값만 통과시켜야 함.
>   * 예: `ORDER BY ${sortKey}` 와 같은 구문은 위험하므로, 사전 정의된 목록에서만 허용.
> * **ORM 및 드라이버의 추가 방어책**
>   * 대부분의 라이브러리는 내부적으로 문자열 escaping, quote 보정, 인코딩 필터링을 수행함.
>   * 그러나 이는 Prepared Statement의 대체가 아니라 보조 수단.
> **결론**
> * SQL Injection 방어의 핵심은 “쿼리 구조와 데이터를 분리”하는 것.
> * Prepared Statement를 기본으로 사용하고, 직접 문자열을 조합해야 하는 경우엔 반드시 입력 검증과 화이트리스트 검사를 병행해야 함.
> * DB 계정의 권한을 최소화하고(WAF, 보안 감사 포함), 공격 발생 시 피해를 제한하는 것도 중요.
